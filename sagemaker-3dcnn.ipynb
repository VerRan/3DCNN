{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import os \n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "将视频数据转换成np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import *\n",
    "# import tqdm\n",
    "from tqdm import *\n",
    "import codecs\n",
    "from keras.utils import np_utils\n",
    "import videoto3d \n",
    "\n",
    "def loaddata(video_dir, vid3d, nclass, result_dir, color=False, skip=True):\n",
    "        files = os.listdir(video_dir)\n",
    "        X = []\n",
    "        labels = []\n",
    "        labellist = []\n",
    "\n",
    "        pbar = tqdm(total=len(files))\n",
    "\n",
    "        for filename in files:\n",
    "            pbar.update(1)\n",
    "            if filename == '.DS_Store':\n",
    "                continue\n",
    "            name = os.path.join(video_dir, filename)\n",
    "            print('filename is ',filename)\n",
    "            label = vid3d.get_UCF_classname(filename)\n",
    "            if label not in labellist:\n",
    "                if len(labellist) >= nclass:\n",
    "                    continue\n",
    "                labellist.append(label)\n",
    "            labels.append(label)\n",
    "            X.append(vid3d.video3d(name, color=color, skip=skip))\n",
    "\n",
    "        pbar.close()\n",
    "        print('result_dir is ',result_dir)\n",
    "        fpath = result_dir + 'classes.txt'\n",
    "        fp = codecs.open(fpath,'a','utf-8')\n",
    "        print('labels length is ',len(labellist))\n",
    "        for i in range(len(labellist)):\n",
    "            fp.write('{}\\n'.format(labellist[i]))\n",
    "\n",
    "        for num, label in enumerate(labellist):\n",
    "            for i in range(len(labels)):\n",
    "                if label == labels[i]:\n",
    "                    labels[i] = num\n",
    "        if color:\n",
    "            return np.array(X).transpose((0, 2, 3, 4, 1)), labels\n",
    "        else:\n",
    "            return np.array(X).transpose((0, 2, 3, 1)), labels\n",
    "\n",
    "        \n",
    "def process():\n",
    "        nclass = 8\n",
    "        depth = 15\n",
    "        skip = False\n",
    "        color = True\n",
    "        img_rows, img_cols, frames = 32, 32, depth\n",
    "\n",
    "        channel = 3 if color else 1\n",
    "#         fname_npz = 'dataset_{}_{}_{}.npz'.format(\n",
    "#                 nclass, depth, skip)\n",
    "        fname_npz = 'np-datasets/train_data.npz'\n",
    "        output = 'default-output/'\n",
    "        videos = 'dataset/'\n",
    "\n",
    "        vid3d = videoto3d.Videoto3D(img_rows, img_cols, frames)\n",
    "        nb_classes = nclass\n",
    "        if os.path.exists(fname_npz):\n",
    "                loadeddata = np.load(fname_npz)\n",
    "                X, Y = loadeddata[\"X\"], loadeddata[\"Y\"]\n",
    "#                 print(X)\n",
    "#                 print(Y)\n",
    "        else:\n",
    "                x, y = loaddata(videos, vid3d, nclass,\n",
    "                                output, color, skip)\n",
    "                X = x.reshape((x.shape[0], img_rows, img_cols, frames, channel))\n",
    "                Y = np_utils.to_categorical(y, nb_classes)\n",
    "\n",
    "                X = X.astype('float32')\n",
    "                np.savez(fname_npz, X=X, Y=Y)\n",
    "        print('Saved dataset to dataset.npz.')\n",
    "        print('X_shape:{}\\nY_shape:{}'.format(X.shape, Y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset to dataset.npz.\n",
      "X_shape:(15, 32, 32, 15, 3)\n",
      "Y_shape:(15, 8)\n"
     ]
    }
   ],
   "source": [
    "process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "将视频数据转换为向量部分代码，独立出来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始上传数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLI上传\n",
    "# aws s3 cp video_sample s3://sagemaker-studio-517141035927-qdeikgx1x88/ --recursive\n",
    "# python s3 demo\n",
    "# https://github.com/aws-samples/aws-python-sample/blob/master/s3_sample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-517141035927/dataset/np'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = sagemaker.Session().upload_data(path='np-datasets', key_prefix='dataset/np')\n",
    "# inputs = 's3://sagemaker-studio-517141035927-qdeikgx1x88/videos/'.format(region)\n",
    "# inputs = {'training': f'file://{customer/video-classify/3DCNN/dataset}'}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     parser.add_argument('--batch', type=int, default=128)\n",
    "#     parser.add_argument('--epoch', type=int, default=100)\n",
    "#     parser.add_argument('--videos', type=str, default='UCF101',\n",
    "#                         help='directory where videos are stored')\n",
    "#     parser.add_argument('--nclass', type=int, default=101)\n",
    "#     parser.add_argument('--output', type=str, required=True)\n",
    "#     parser.add_argument('--color', type=bool, default=False)\n",
    "#     parser.add_argument('--skip', type=bool, default=True)\n",
    "#     parser.add_argument('--depth', type=int, default=10)\n",
    "    \n",
    "hyperparameters = {'epoch': 3, \n",
    "                   'data_dir': '/opt/ml/input/data/training',\n",
    "                   'batch': 3, \n",
    "#                    'videos': 'file://home/sagemaker-user/customer/video-classify/3DCNN/dataset', \n",
    "#                    'videos':'/opt/ml/input/data/training',\n",
    "                   'nclass': 8,\n",
    "                   'output': '/opt/ml/output',\n",
    "                  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码读取github方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git_config = {'repo': 'https://github.com/VerRan/3DCNN.git', 'branch': 'script'}\n",
    "# estimator = TensorFlow(entry_point='sagemaker-3dcnn.py',\n",
    "# #                        source_dir='char-rnn-tensorflow',\n",
    "#                        git_config=git_config,\n",
    "#                        train_instance_type='ml.c4.xlarge', # Executes training in a ml.c4.xlarge instance\n",
    "#                        train_instance_count=1,\n",
    "#                        hyperparameters=hyperparameters,\n",
    "#                        role=sagemaker.get_execution_role(),\n",
    "#                        framework_version='1.15.2',\n",
    "#                        py_version='py3',\n",
    "#                        script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地调试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"sagemaker-3dcnn.py\", line 110, in <module>\n",
      "    main()\n",
      "  File \"sagemaker-3dcnn.py\", line 53, in main\n",
      "    parser.add_argument('--hosts', type=list, default=json.loads(os.environ.get('SM_HOSTS')))\n",
      "NameError: name 'json' is not defined\n"
     ]
    }
   ],
   "source": [
    "! python3 sagemaker-3dcnn.py --batch 3 --data_dir np-datasets --epoch 3 --output default-output  --nclass 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point='sagemaker-3dcnn.py',\n",
    "#                        source_dir='char-rnn-tensorflow',\n",
    "#                        git_config=git_config,\n",
    "#                        dependencies=['/usr/local/lib/python3.6/dist-packages/opencv_python_headless-4.4.0.46.dist-info','videoto3d.py'],\n",
    "                       train_instance_type='ml.c4.xlarge', # Executes training in a ml.c4.xlarge instance\n",
    "                       train_instance_count=1,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-16 13:34:17 Starting - Starting the training job...\n",
      "2020-12-16 13:34:19 Starting - Launching requested ML instances......\n",
      "2020-12-16 13:35:29 Starting - Preparing the instances for training......\n",
      "2020-12-16 13:36:42 Downloading - Downloading input data...\n",
      "2020-12-16 13:37:03 Training - Downloading the training image..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:31,001 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:31,006 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:31,531 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:31,548 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:31,563 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:31,574 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"nclass\": 8,\n",
      "        \"output\": \"/opt/ml/output\",\n",
      "        \"batch\": 3,\n",
      "        \"epoch\": 3,\n",
      "        \"model_dir\": \"s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/model\",\n",
      "        \"data_dir\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2020-12-16-13-34-16-111\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sagemaker-3dcnn\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sagemaker-3dcnn.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch\":3,\"data_dir\":\"/opt/ml/input/data/training\",\"epoch\":3,\"model_dir\":\"s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/model\",\"nclass\":8,\"output\":\"/opt/ml/output\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sagemaker-3dcnn.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sagemaker-3dcnn\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch\":3,\"data_dir\":\"/opt/ml/input/data/training\",\"epoch\":3,\"model_dir\":\"s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/model\",\"nclass\":8,\"output\":\"/opt/ml/output\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-12-16-13-34-16-111\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/source/sourcedir.tar.gz\",\"module_name\":\"sagemaker-3dcnn\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sagemaker-3dcnn.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch\",\"3\",\"--data_dir\",\"/opt/ml/input/data/training\",\"--epoch\",\"3\",\"--model_dir\",\"s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/model\",\"--nclass\",\"8\",\"--output\",\"/opt/ml/output\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_NCLASS=8\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH=3\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=3\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/model\u001b[0m\n",
      "\u001b[34mSM_HP_DATA_DIR=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 sagemaker-3dcnn.py --batch 3 --data_dir /opt/ml/input/data/training --epoch 3 --model_dir s3://sagemaker-us-west-2-517141035927/tensorflow-training-2020-12-16-13-34-16-111/model --nclass 8 --output /opt/ml/output\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mModel: \"sequential_1\"\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mconv3d_1 (Conv3D)            (None, 32, 32, 15, 32)    2624      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_1 (Activation)    (None, 32, 32, 15, 32)    0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_2 (Conv3D)            (None, 32, 32, 15, 32)    27680     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_2 (Activation)    (None, 32, 32, 15, 32)    0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling3d_1 (MaxPooling3 (None, 11, 11, 5, 32)     0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_1 (Dropout)          (None, 11, 11, 5, 32)     0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_3 (Conv3D)            (None, 11, 11, 5, 64)     55360     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_3 (Activation)    (None, 11, 11, 5, 64)     0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_4 (Conv3D)            (None, 11, 11, 5, 64)     110656    \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_4 (Activation)    (None, 11, 11, 5, 64)     0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling3d_2 (MaxPooling3 (None, 4, 4, 2, 64)       0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_2 (Dropout)          (None, 4, 4, 2, 64)       0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mflatten_1 (Flatten)          (None, 2048)              0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 512)               1049088   \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_3 (Dropout)          (None, 512)               0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_2 (Dense)              (None, 8)                 4104      \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1,249,512\u001b[0m\n",
      "\u001b[34mTrainable params: 1,249,512\u001b[0m\n",
      "\u001b[34mNon-trainable params: 0\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTrain on 12 samples, validate on 3 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/3\u001b[0m\n",
      "\n",
      "2020-12-16 13:37:44 Uploading - Uploading generated training model\u001b[34m 3/12 [======>.......................] - ETA: 4s - loss: 2.3353 - accuracy: 0.0000e+00\n",
      " 6/12 [==============>...............] - ETA: 1s - loss: 3.0811 - accuracy: 0.0000e+00\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2.9649 - accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34m12/12 [==============================] - 2s 193ms/step - loss: 3.0634 - accuracy: 0.0000e+00 - val_loss: 3.4086 - val_accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34mEpoch 2/3\n",
      "\u001b[0m\n",
      "\u001b[34m 3/12 [======>.......................] - ETA: 0s - loss: 2.2126 - accuracy: 0.0000e+00\n",
      " 6/12 [==============>...............] - ETA: 0s - loss: 2.6307 - accuracy: 0.0000e+00\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2.2811 - accuracy: 0.1111    \u001b[0m\n",
      "\u001b[34m12/12 [==============================] - 1s 67ms/step - loss: 2.2581 - accuracy: 0.0833 - val_loss: 3.7982 - val_accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34mEpoch 3/3\n",
      "\n",
      " 3/12 [======>.......................] - ETA: 0s - loss: 2.2315 - accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34m 6/12 [==============>...............] - ETA: 0s - loss: 2.1388 - accuracy: 0.0000e+00\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2.0232 - accuracy: 0.1111    \u001b[0m\n",
      "\u001b[34m12/12 [==============================] - 1s 66ms/step - loss: 2.0142 - accuracy: 0.0833 - val_loss: 4.3102 - val_accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:39,766 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2020-12-16 13:37:39,766 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-16 13:37:52 Completed - Training job completed\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': inputs})"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
